{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deskew(img):\n",
    "    m = cv2.moments(img)\n",
    "    if abs(m['mu02']) < 1e-2:\n",
    "        return img.copy()\n",
    "    skew = m['mu11']/m['mu02']\n",
    "    M = np.float32([[1, skew, -0.5*SZ*skew], [0, 1, 0]])\n",
    "    img = cv2.warpAffine(img,M,(SZ, SZ),flags=affine_flags)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#img = cv2.imread(\"vi_osmo_numbers/color/Photo 2-14-17, 10 44 20 AM.jpg\", cv2.IMREAD_COLOR)\n",
    "img = cv2.imread(\"vi_osmo_numbers/cropped_number_rotated/o2.jpg_cropped.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.imshow(img)\n",
    "#plt.show()\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#cv2.imshow('imgray',imgray)\n",
    "\n",
    "edge_wide = cv2.Canny(imgray, 10, 200)\n",
    "edge_tight = cv2.Canny(imgray, 225, 250)\n",
    "edge_custom = cv2.Canny(imgray, 200, 400)\n",
    "\n",
    "sigma=0.33\n",
    "# compute the median of the single channel pixel intensities\n",
    "v = np.median(imgray)\n",
    "\n",
    "# apply automatic Canny edge detection using the computed median\n",
    "lower = int(max(0, (1.0 - sigma) * v))\n",
    "upper = int(min(255, (1.0 + sigma) * v))\n",
    "edge_auto = cv2.Canny(imgray, lower, upper)\n",
    "\n",
    "cv2.imshow('edge_wide', edge_wide)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('edge_tight', edge_tight)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('edge_custom', edge_custom)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('edge_auto', edge_auto)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_blurred = cv2.medianBlur(imgray, 5)\n",
    "\n",
    "ret,th1 = cv2.threshold(img_blurred,127,255,cv2.THRESH_BINARY_INV)\n",
    "th2 = cv2.adaptiveThreshold(img_blurred,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv2.THRESH_BINARY_INV,11,2)\n",
    "th3 = cv2.adaptiveThreshold(img_blurred,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY_INV,11,2)\n",
    "\n",
    "otsu_threshold1, th4 = cv2.threshold(imgray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "\n",
    "#otsu_threshold2, th5 = cv2.threshold(img_blurred, 0, 255, cv2.THRESH_BINARYINV+cv2.THRESH_OTSU)\n",
    "\n",
    "#cv2.imshow(\"Global Thresholding (v = 127)\", th1)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.imshow(\"Adaptive Mean Thresholding\", th2)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.imshow(\"Adaptive Gaussian Thresholding\", th3)\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow(\"Otsu th4\", th4)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#cv2.imshow(\"Otsu th5\", th4)\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cimg, contours, hierarchy = cv2.findContours(th2, 1, 2)\n",
    "cnt = contours[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv2.imshow(\"contours\", cnt)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def run_main():\n",
    "#     cap = cv2.VideoCapture(0)\n",
    "#     cap.set(cv2.cv.CV_CAP_PROP_FRAME_WIDTH, 1280)\n",
    "#     cap.set(cv2.cv.CV_CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "#     while(True):\n",
    "    #ret, frame = cap.read()\n",
    "    #roi = frame[0:500, 0:500]\n",
    "    roi = cv2.imread(\"vi_osmo_numbers/o2.jpg\")\n",
    "    #roi = cv2.imread(\"coin_img.png\")\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray_blur = cv2.GaussianBlur(gray, (15, 15), 0)\n",
    "    thresh = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV, 11, 1)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE,\n",
    "        kernel, iterations=4)\n",
    "\n",
    "    closing = cv2.bitwise_not(closing)\n",
    "    cont_img = closing.copy()\n",
    "    cimg, contours, hierarchy = cv2.findContours(cont_img, cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        #print area\n",
    "        #perimeter = cv2.arcLength(cnt, True)\n",
    "        #print perimeter\n",
    "#         x,y,w,h = cv2.boundingRect(cnt)\n",
    "#         cv2.rectangle(roi,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "#         cv2.waitKey(0)\n",
    "        \n",
    "#         if area < 2000 or area > 4000:\n",
    "#         #if area > 100:\n",
    "#              continue\n",
    "\n",
    "        if len(cnt) < 5:\n",
    "            continue\n",
    "\n",
    "        #ellipse = cv2.fitEllipse(cnt)\n",
    "        #cv2.ellipse(roi, ellipse, (0,255,0), 2)\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "    cv2.imshow(\"Morphological Closing\", closing)\n",
    "    cv2.imshow(\"Adaptive Thresholding\", thresh)\n",
    "    cv2.imshow('Contours', roi)\n",
    "\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "#     cap.release()\n",
    "\n",
    "#     x,y,w,h = cv2.boundingRect(contours[0])\n",
    "#     cv2.rectangle(roi,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "#     cv2.waitKey(0)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gray.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import numpy.linalg as la\n",
    "\n",
    "\n",
    "SZ = 20\n",
    "affine_flags = cv2.WARP_INVERSE_MAP|cv2.INTER_LINEAR\n",
    "def deskew(img):\n",
    "    size = (img.shape[1], img.shape[0])\n",
    "    m = cv2.moments(img)\n",
    "    if abs(m['mu02']) < 1e-2:\n",
    "        return img.copy()\n",
    "    skew = m['mu11']/m['mu02']\n",
    "    M = np.float32([[1, skew, -0.5*SZ*skew], [0, 1, 0]])\n",
    "    img = cv2.warpAffine(img, M, size, flags=affine_flags)\n",
    "    return img\n",
    "\n",
    "for n in xrange(1, 10):\n",
    "    filename = \"o\" + str(n) + \".jpg\"\n",
    "    img = cv2.imread(\"vi_osmo_numbers/color/\" + filename)\n",
    "    #roi = cv2.imread(\"coin_img.png\")\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # filter for edge\n",
    "    #gray_blur = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "    gray_blur = cv2.bilateralFilter(gray, 11, 13, 13)\n",
    "    #gray_blur = gray\n",
    "\n",
    "    sigma=0.33\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(gray_blur)\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(gray_blur, lower, upper)\n",
    "    #otsu_threshold, edged = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    #edged = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 1)\n",
    "    # cv2.imshow(\"edged\", edged)\n",
    "    # cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "\n",
    "    # find contours in the edged image, keep only the largest\n",
    "    # ones, and initialize our screen contour\n",
    "    (cimg, cnts, hierarchy) = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #(cimg, cnts, hierarchy) = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    #(cimg, cnts, hierarchy) = cv2.findContours(edged.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "    #cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:5]\n",
    "    cnts_idxes = sorted(range(len(cnts)), key=lambda k: cv2.contourArea(cnts[k]), \n",
    "                        reverse = True)[:10]\n",
    "    #hierarchy = sorted(hierarchy, key = cv2.contourArea, reverse = True)[:5]\n",
    "    screenCnt = None\n",
    "\n",
    "    #print \"length of hierarchy[0]\", len(hierarchy[0])\n",
    "    #print \"length of cnts_idxes\", len(cnts_idxes)\n",
    "\n",
    "    bFoundTarget = False\n",
    "    # loop over our contour\n",
    "    #for c, hi in zip(cnts, hierarchy[0]):\n",
    "    for ci in cnts_idxes:\n",
    "        c = cnts[ci]\n",
    "        hi = hierarchy[0][ci]\n",
    "\n",
    "    #     # display contours and its area\n",
    "    #     mask = np.zeros(gray.shape,np.uint8)\n",
    "    #     cv2.drawContours(mask,[c],0,255,-1)\n",
    "    #     cv2.imshow(str(ci)+\"mask\", mask)\n",
    "\n",
    "        #print cv2.isContourConvex(c)\n",
    "        #print hi\n",
    "        #if hi[0] == -1 and hi[1] == -1 and hi[2] == -1 and hi[3] != -1:\n",
    "        #if hi[0] == -1 and hi[1] == -1 and hi[2] != -1 and hi[3] != -1:\n",
    "        if hi[3] != -1:\n",
    "    #         # display contours and its area\n",
    "    #         mask = np.zeros(gray.shape,np.uint8)\n",
    "    #         cv2.drawContours(mask,[c],0,255,-1)\n",
    "    #         cv2.imshow(str(ci)+\"mask\", mask)\n",
    "\n",
    "    #         # draw contours on original image\n",
    "    #         img_copy = img.copy()\n",
    "    #         cv2.drawContours(img_copy, [c], -1, (0, 255, 0), 3)\n",
    "    #         cv2.imshow(str(ci)+\"contours\", img_copy)\n",
    "    #         #cv2.waitKey(0)\n",
    "\n",
    "            # approximate the contour\n",
    "            peri = cv2.arcLength(c, True)\n",
    "            approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "\n",
    "            if len(approx) == 4:\n",
    "                continue\n",
    "\n",
    "    #         # crop target part\n",
    "    #         x,y,w,h = cv2.boundingRect(c)\n",
    "    #         cropped = img.copy()[y:y+h,x:x+w]\n",
    "    #         #cropped_gray = gray[y:y+h,x:x+w]\n",
    "    #         #cropped = img.copy()[y+5:y+h-5,x+5:x+w-5]\n",
    "    #         #cropped_gray = gray[y+5:y+h-5,x+5:x+w-5]\n",
    "    #         #cv2.imshow(\"cropped\", cropped)\n",
    "\n",
    "            # check parent part\n",
    "            parent_idx = hi[3] \n",
    "            while parent_idx != -1:\n",
    "                #print \"parent_idx\", parent_idx\n",
    "                # parent contour\n",
    "                parent_c = cnts[parent_idx]\n",
    "                parent_hi = hierarchy[0][parent_idx]\n",
    "                # approximate the contour\n",
    "                peri = cv2.arcLength(parent_c, True)\n",
    "                approx = cv2.approxPolyDP(parent_c, 0.11 * peri, True)        \n",
    "                # if our approximated contour has four points, then\n",
    "                # we can assume that we have found our screen\n",
    "                #print \"parent approx: \", len(approx)\n",
    "                x,y,w,h = cv2.boundingRect(parent_c)\n",
    "                aspect_ratio = w / h\n",
    "                #print \"aspect_ratio of \", parent_idx, aspect_ratio\n",
    "                if aspect_ratio >=1 and len(approx) == 4:\n",
    "                    #print \"aspect_ratio of \", parent_idx, aspect_ratio\n",
    "                    parent_cropped = img.copy()[y:y+h,x:x+w]\n",
    "                    #cropped_gray = gray[y:y+h,x:x+w]\n",
    "                    #cropped = img.copy()[y+5:y+h-5,x+5:x+w-5]\n",
    "                    #cropped_gray = gray[y+5:y+h-5,x+5:x+w-5]                \n",
    "\n",
    "#                     # for child - target number\n",
    "#                     child_idx = parent_hi[2]\n",
    "#                     child_c = cnts[child_idx]\n",
    "#                     # draw contours on original image\n",
    "#                     img_copy = img.copy()\n",
    "#                     cv2.drawContours(img_copy, [child_c], -1, (0, 255, 0), 3)\n",
    "#                     cv2.imshow(str(child_idx)+\"contours\", img_copy)\n",
    "#                     cv2.imshow(\"p\"+str(child_idx), parent_cropped)\n",
    "\n",
    "                    bFoundTarget = True\n",
    "                    break\n",
    "                else:\n",
    "                    parent_idx = parent_hi[3]\n",
    "\n",
    "            #\n",
    "            if bFoundTarget:\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "    #     # display contours and its area\n",
    "    #     mask = np.zeros(gray.shape,np.uint8)\n",
    "    #     cv2.drawContours(mask,[c],0,255,-1)\n",
    "    #     cv2.imshow(str(hi), mask)\n",
    "    #     cv2.waitKey(0)\n",
    "\n",
    "    #     x,y,w,h = cv2.boundingRect(c)\n",
    "    #     aspect_ratio = round(w / h);\n",
    "    #     #print aspect_ratio\n",
    "\n",
    "    #     #f h[3] != -1:\n",
    "    #     if aspect_ratio == 1:\n",
    "    #         #print \"aaaa\", h        \n",
    "    #         #,y,w,h = cv2.boundingRect(c)\n",
    "    #         #spect_ratio = round(w / h);\n",
    "    #         #print aspect_ratio\n",
    "    # #         if aspect_ratio == 1:\n",
    "    #         mask = img.copy()[y:y+h,x:x+w]\n",
    "    #         mask_gray = gray[y:y+h,x:x+w]\n",
    "    #         mask_deskewed = deskew(mask_gray)\n",
    "    #         #cv2.imshow(\"shape\", mask)\n",
    "    #         #cv2.waitKey(0)\n",
    "    #         #break\n",
    "\n",
    "\n",
    "\n",
    "    #     # approximate the contour\n",
    "    #     peri = cv2.arcLength(c, True)\n",
    "    #     #approx = cv2.approxPolyDP(c, 0.02 * peri, True)    \n",
    "    #     approx = cv2.approxPolyDP(c, 0.002 * peri, True)\n",
    "\n",
    "\n",
    "        # if our approximated contour has four points, then\n",
    "        # we can assume that we have found our screen\n",
    "    #     if len(approx) == 4:\n",
    "    #         screenCnt = approx\n",
    "    #         #print screenCnt\n",
    "    #         #print IsSquare(approx)\n",
    "\n",
    "    #         x,y,w,h = cv2.boundingRect(c)\n",
    "    #         cropped = img.copy()[y:y+h,x:x+w]\n",
    "            #cropped_gray = gray[y:y+h,x:x+w]\n",
    "            #cropped = img.copy()[y+5:y+h-5,x+5:x+w-5]\n",
    "            #cropped_gray = gray[y+5:y+h-5,x+5:x+w-5]\n",
    "\n",
    "    #         cropped_edged = edged[y+5:y+h-5,x+5:x+w-5]        \n",
    "    #         (_, cns, __) = cv2.findContours(cropped_edged.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "    #         cns = sorted(cns, key = cv2.contourArea, reverse = True)[:5]\n",
    "    #         for cn, j in zip(cns, __[0]):\n",
    "    #             #print cv2.isContourConvex(cn)            \n",
    "    #             #print j\n",
    "    #             # display contours and its area\n",
    "    #             mask = np.zeros(cropped_edged.shape,np.uint8)\n",
    "    #             cv2.drawContours(mask,[cn],0,255,-1)\n",
    "    #             cv2.imshow(str(j), mask)\n",
    "    #             cv2.waitKey(0)\n",
    "\n",
    "            #cropped_deskewed = deskew(cropped_gray)\n",
    "\n",
    "    #         cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "    #         rect = cv2.minAreaRect(c)\n",
    "    #         box = cv2.boxPoints(rect)\n",
    "    #         box = np.int0(box)\n",
    "    #         cv2.drawContours(img,[box],0,(0,0,255),2)\n",
    "\n",
    "    #         #orientation\n",
    "    #         (x,y),(MA,ma),angle = cv2.fitEllipse(c)\n",
    "    #         print angle\n",
    "            #print len(c)\n",
    "            #pixelpoints = np.transpose(np.nonzero(mask))\n",
    "            #pixelpoints = cv2.findNonZero(mask)        \n",
    "\n",
    "            #break\n",
    "\n",
    "    # Threshold cropped so it becomes binary\n",
    "    #otsu_threshold, cropped_binary = cv2.threshold(cropped_gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    # kernel = np.ones((3, 3), np.uint8)\n",
    "    # cropped_binary = cv2.morphologyEx(cropped_binary, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    # #closing = cv2.bitwise_not(closing)\n",
    "\n",
    "    #cv2.imshow(\"edged\", edged)\n",
    "    #cv2.drawContours(img, [screenCnt], -1, (0, 255, 0), 3)\n",
    "    #cv2.drawContours(img, [box], -1, (0, 255, 0), 3)\n",
    "    #cv2.imshow(\"digit tag\", img_copy)\n",
    "    #cv2.imshow(\"cropped\", cropped)\n",
    "    #cv2.imshow(\"gray\", mask_gray)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyWindow(\"gray\")\n",
    "    #cv2.imshow(\"deskewed\", mask_deskewed)\n",
    "    #cv2.imshow(\"cropped_edged\", cropped_edged)\n",
    "\n",
    "    #cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    #horizontal_cropped = cv2.flip( mask, 1 )\n",
    "    #cv2.imwrite(filename + \"_cropped.png\", cropped)\n",
    "    cv2.imwrite(filename + \"_numbox.png\", parent_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print otsu_threshold\n",
    "\n",
    "print len(cnts)\n",
    "\n",
    "\n",
    "#cv2.imwrite(\"cropped.png\", horizontal_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#horizontal_cropped.shape\n",
    "for s in stats:\n",
    "    print s[cv2.CC_STAT_AREA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You need to choose 4 or 8 for connectivity type\n",
    "connectivity = 4  \n",
    "# Perform the operation\n",
    "output = cv2.connectedComponentsWithStats(cropped_binary, connectivity, cv2.CV_32S)\n",
    "# Get the results\n",
    "# The first cell is the number of labels\n",
    "num_labels = output[0]\n",
    "# The second cell is the label matrix\n",
    "labels = output[1]\n",
    "# The third cell is the stat matrix\n",
    "stats = output[2]\n",
    "# The fourth cell is the centroid matrix\n",
    "centroids = output[3]\n",
    "\n",
    "# loop over the unique components\n",
    "for l in np.unique(labels):\n",
    "    # if this is the background label, ignore it\n",
    "    if l == 0:\n",
    "        continue\n",
    "\n",
    "    # otherwise, construct the label mask and count the\n",
    "    # number of pixels \n",
    "    labelMask = np.zeros(cropped_binary.shape, dtype=\"uint8\")\n",
    "    labelMask[labels == l] = 255\n",
    "    cv2.circle(labelMask, (int(centroids[l][0]), int(centroids[l][1])), 5, (255,0,0), -1)\n",
    "    #numPixels = cv2.countNonZero(labelMask)\n",
    "    cv2.imshow(l.tostring(), labelMask)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centroids[l][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cropped_dpi = 635, 635\n",
    "\n",
    "horizontal_cropped = cv2.flip( cropped, 1 )\n",
    "rgb_im = cv2.cvtColor(horizontal_cropped, cv2.COLOR_BGR2RGB)\n",
    "pil_im = Image.fromarray(rgb_im)\n",
    "#pil_im.info[\"dpi\"] = cropped_dpi\n",
    "#pil_im.info[\"default\"] = [635, 635]\n",
    "pil_im.info[\"dpi\"] = (300, 300)\n",
    "\n",
    "#print pil_im.info[\"dpi\"]\n",
    "#print pil_im.info[\"default\"]\n",
    "\n",
    "#pil_im.save(\"pil_cropped.png\")\n",
    "\n",
    "pil_im.save(\"pil_cropped.png\", dpi=(300, 300))\n",
    "\n",
    "#im2 = Image.open(\"pil_cropped.png\")\n",
    "#im2.info\n",
    "\n",
    "#pil_im = pil_im.resize((635, 635), Image.ANTIALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import Image\n",
    "\n",
    "#pil_im = Image.fromarray(horizontal_cropped)\n",
    "#pil_im = Image.fromarray(np.roll(horizontal_cropped, 1, axis=-1))\n",
    "\n",
    "\n",
    "\n",
    "recognizedTxt = pytesseract.image_to_string(pil_im, lang='eng', \n",
    "                                  config=\"-psm 10\")\n",
    "#pil_im.show()\n",
    "\n",
    "import string\n",
    "all = string.maketrans('','')\n",
    "nodigs = all.translate(all, string.digits)\n",
    "print recognizedTxt.translate(all, nodigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
