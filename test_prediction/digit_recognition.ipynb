{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import Image\n",
    "import pytesseract\n",
    "import string\n",
    "\n",
    "\n",
    "filename = \"o4.jpg\"\n",
    "filepath = \"vi_osmo_numbers/color/\" + filename\n",
    "img = cv2.imread(filepath)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# filter for edge\n",
    "#gray_blur = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "gray_blur = cv2.bilateralFilter(gray, 11, 13, 13)\n",
    "#gray_blur = gray\n",
    "\n",
    "sigma=0.33\n",
    "# compute the median of the single channel pixel intensities\n",
    "v = np.median(gray_blur)\n",
    "# apply automatic Canny edge detection using the computed median\n",
    "lower = int(max(0, (1.0 - sigma) * v))\n",
    "upper = int(min(255, (1.0 + sigma) * v))\n",
    "edged = cv2.Canny(gray_blur, lower, upper)\n",
    "#otsu_threshold, edged = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "#edged = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 1)\n",
    "# cv2.imshow(\"edged\", edged)\n",
    "# cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "# find contours in the edged image, keep only the largest\n",
    "# ones, and initialize our screen contour\n",
    "(cimg, cnts, hierarchy) = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#(cimg, cnts, hierarchy) = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "#(cimg, cnts, hierarchy) = cv2.findContours(edged.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "#cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:5]\n",
    "cnts_idxes = sorted(range(len(cnts)), key=lambda k: cv2.contourArea(cnts[k]), \n",
    "                    reverse = True)[:10]\n",
    "#screenCnt = None\n",
    "\n",
    "bFoundTarget = False\n",
    "# loop over our contour\n",
    "#for c, hi in zip(cnts, hierarchy[0]):\n",
    "for ci in cnts_idxes:\n",
    "    c = cnts[ci]\n",
    "    hi = hierarchy[0][ci]\n",
    "\n",
    "#     # display contours and its area\n",
    "#     mask = np.zeros(gray.shape,np.uint8)\n",
    "#     cv2.drawContours(mask,[c],0,255,-1)\n",
    "#     cv2.imshow(str(ci)+\"mask\", mask)\n",
    "\n",
    "    #print cv2.isContourConvex(c)\n",
    "    #print hi\n",
    "    #if hi[0] == -1 and hi[1] == -1 and hi[2] == -1 and hi[3] != -1:\n",
    "    #if hi[0] == -1 and hi[1] == -1 and hi[2] != -1 and hi[3] != -1:\n",
    "    if hi[3] != -1:\n",
    "        \n",
    "#         # draw contours on original image\n",
    "#         img_copy = img.copy()\n",
    "#         cv2.drawContours(img_copy, [c], -1, (0, 255, 0), 3)\n",
    "#         cv2.imshow(str(ci)+\"contours\", img_copy)\n",
    "#         #cv2.waitKey(0)\n",
    "\n",
    "        # approximate the contour\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "\n",
    "        if len(approx) == 4:\n",
    "            continue\n",
    "\n",
    "        # CROP ONLY THE NUMBER\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        cropped = img.copy()[y:y+h,x:x+w]\n",
    "        #cropped_gray = gray[y:y+h,x:x+w]\n",
    "        #cropped = img.copy()[y+5:y+h-5,x+5:x+w-5]\n",
    "        #cropped_gray = gray[y+5:y+h-5,x+5:x+w-5]\n",
    "        cv2.imshow(\"cropped\", cropped)\n",
    "\n",
    "        # check parent part\n",
    "        parent_idx = hi[3] \n",
    "        while parent_idx != -1:\n",
    "            #print \"parent_idx\", parent_idx\n",
    "            # parent contour\n",
    "            parent_c = cnts[parent_idx]\n",
    "            parent_hi = hierarchy[0][parent_idx]\n",
    "            # approximate the contour\n",
    "            peri = cv2.arcLength(parent_c, True)\n",
    "            approx = cv2.approxPolyDP(parent_c, 0.11 * peri, True)        \n",
    "            # if our approximated contour has four points, then\n",
    "            # we can assume that we have found our screen\n",
    "            #print \"parent approx: \", len(approx)\n",
    "            x,y,w,h = cv2.boundingRect(parent_c)\n",
    "            aspect_ratio = w / h\n",
    "            #print \"aspect_ratio of \", parent_idx, aspect_ratio\n",
    "            if aspect_ratio >=1 and len(approx) == 4:\n",
    "                #print \"aspect_ratio of \", parent_idx, aspect_ratio\n",
    "                parent_cropped = img.copy()[y:y+h,x:x+w]\n",
    "                #cropped_gray = gray[y:y+h,x:x+w]\n",
    "                #cropped = img.copy()[y+5:y+h-5,x+5:x+w-5]\n",
    "                #cropped_gray = gray[y+5:y+h-5,x+5:x+w-5]                \n",
    "\n",
    "                # for child - target number\n",
    "                child_idx = parent_hi[2]\n",
    "                child_c = cnts[child_idx]\n",
    "                # draw contours on original image\n",
    "                img_copy = img.copy()\n",
    "                cv2.drawContours(img_copy, [child_c], -1, (0, 255, 0), 3)\n",
    "                cv2.imshow(str(child_idx)+\"contours\", img_copy)\n",
    "                cv2.imshow(\"p\"+str(child_idx), parent_cropped)\n",
    "\n",
    "                bFoundTarget = True\n",
    "                break\n",
    "            else:\n",
    "                parent_idx = parent_hi[3]\n",
    "\n",
    "        #\n",
    "        if bFoundTarget:\n",
    "            break\n",
    "\n",
    "# Threshold cropped so it becomes binary\n",
    "#otsu_threshold, cropped_binary = cv2.threshold(cropped_gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "# kernel = np.ones((3, 3), np.uint8)\n",
    "# cropped_binary = cv2.morphologyEx(cropped_binary, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "# #closing = cv2.bitwise_not(closing)\n",
    "\n",
    "#cv2.imshow(\"edged\", edged)\n",
    "#cv2.drawContours(img, [screenCnt], -1, (0, 255, 0), 3)\n",
    "#cv2.drawContours(img, [box], -1, (0, 255, 0), 3)\n",
    "#cv2.imshow(\"digit tag\", img_copy)\n",
    "#cv2.imshow(\"cropped\", cropped)\n",
    "#cv2.imshow(\"gray\", mask_gray)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyWindow(\"gray\")\n",
    "#cv2.imshow(\"deskewed\", mask_deskewed)\n",
    "#cv2.imshow(\"cropped_edged\", cropped_edged)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#horizontal_cropped = cv2.flip( mask, 1 )\n",
    "#cv2.imwrite(filename + \"_cropped.png\", cropped)\n",
    "#cv2.imwrite(filename + \"_numbox.png\", parent_cropped)       \n",
    "\n",
    "\n",
    "# # preprocess image for Tesseract 4        \n",
    "# #horizontal_cropped = cv2.flip( parent_cropped, 1 )\n",
    "# horizontal_cropped = parent_cropped\n",
    "# rgb_im = cv2.cvtColor(horizontal_cropped, cv2.COLOR_BGR2RGB)\n",
    "# pil_im = Image.fromarray(rgb_im)\n",
    "# pil_im.info[\"dpi\"] = (300, 300)\n",
    "# pil_im.save(\"pil_cropped.png\")\n",
    "\n",
    "# # call Tesseract\n",
    "# recognizedTxt = pytesseract.image_to_string(pil_im, lang='eng', config=\"-psm 13\")\n",
    "# print recognizedTxt\n",
    "\n",
    "\n",
    "#pil_im.show()\n",
    "\n",
    "# # remove non-digits\n",
    "# allchars = string.maketrans('','')\n",
    "# nodigs = allchars.translate(allchars, string.digits)\n",
    "# print recognizedTxt.translate(allchars, nodigs)\n",
    "\n",
    "# cv2.imshow(\"edged\", edged)\n",
    "# cv2.drawContours(img, [screenCnt], -1, (0, 255, 0), 3)\n",
    "# cv2.imshow(\"digit tag\", img)\n",
    "# cv2.imshow(\"cropped\", cropped)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#======= PREDICTION USING TRAINED MODEL ==============\n",
    "\n",
    "\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "# load the model from disk\n",
    "model_filename = \"sklearn_model_01.sav\"\n",
    "loaded_model = pickle.load(open(model_filename, 'rb'))\n",
    "\n",
    "# constants\n",
    "pixel_depth = 255.0\n",
    "tupleDim = (28, 28)\n",
    "\n",
    "# preprocess image\n",
    "cropped_gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)\n",
    "# binarization using Otsu method\n",
    "_, cropped_binarized = cv2.threshold(cropped_gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "#\n",
    "cropped_resized = cv2.resize(cropped_binarized, tupleDim, interpolation = cv2.INTER_LINEAR)\n",
    "## display binarized image\n",
    "#cv2.imshow(\"cb\", cropped_resized)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "#print type(cropped_resized)\n",
    "#print cropped_resized.shape\n",
    "\n",
    "# run prediction\n",
    "img_data = (cropped_resized.astype(float) - pixel_depth / 2) / pixel_depth\n",
    "img_height, img_width = img_data.shape\n",
    "ax_2D = img_data.reshape( (1, img_height*img_width) )\n",
    "#print(ax_2D.shape)    \n",
    "predictions =  loaded_model.predict(ax_2D)\n",
    "print(filepath, predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
