{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "#\n",
    "pixel_depth = 255.0\n",
    "\n",
    "# load the model from disk\n",
    "model_filename = \"sklearn_model_01.sav\"\n",
    "loaded_model = pickle.load(open(model_filename, 'rb'))\n",
    "#result = loaded_model.score(X_test_2D, y_test)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('vi_osmo_numbers/cropped_number/o4.jpg_cropped.png', 4)\n",
      "('vi_osmo_numbers/cropped_number/o7.jpg_cropped.png', 7)\n",
      "('vi_osmo_numbers/cropped_number/o6.jpg_cropped.png', 6)\n",
      "('vi_osmo_numbers/cropped_number/o3.jpg_cropped.png', 3)\n",
      "('vi_osmo_numbers/cropped_number/o9.jpg_cropped.png', 9)\n",
      "('vi_osmo_numbers/cropped_number/o2.jpg_cropped.png', 2)\n",
      "('vi_osmo_numbers/cropped_number/o5.jpg_cropped.png', 5)\n",
      "('vi_osmo_numbers/cropped_number/o1.jpg_cropped.png', 1)\n",
      "('vi_osmo_numbers/cropped_number/o0.jpg_cropped.png', 0)\n",
      "('vi_osmo_numbers/cropped_number/o8.jpg_cropped.png', 8)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "strFolder = 'vi_osmo_numbers/cropped_number'\n",
    "lstFiles = [f for f in os.listdir(strFolder) if os.path.isfile(strFolder+'/'+f)]\n",
    "tupleDim = (28, 28)\n",
    "#print lstFiles\n",
    "for fname in lstFiles:\n",
    "    f = '/'.join([strFolder, fname])\n",
    "    #print f\n",
    "    # read\n",
    "    img = cv2.imread(f)\n",
    "    # to grayscale\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # binarization using Otsu method\n",
    "    otsu_threshold, img_binarized = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    ## display binarized image\n",
    "    #cv2.imshow(\"binarized\", img_binarized)\n",
    "    #cv2.waitKey(0)\n",
    "    \n",
    "    img_resized = cv2.resize(img_binarized, tupleDim, interpolation = cv2.INTER_LINEAR)\n",
    "    #cv2.imshow(\"resized\", img_resized)\n",
    "    #cv2.waitKey(0)\n",
    "    \n",
    "    ## write a binarized image to file \n",
    "    ##cv2.imwrite('/'.join([strFolder, \"binarized\", fname]), img_binarized)\n",
    "    afile = '/'.join([strFolder, \"binarized\", fname])\n",
    "    cv2.imwrite(afile, img_resized)\n",
    "    \n",
    "    # predict class\n",
    "    img = ndimage.imread(afile)\n",
    "    img = (ndimage.imread(afile).astype(float) - pixel_depth / 2) / pixel_depth\n",
    "    img_height, img_width = img.shape\n",
    "    ax_2D = img.reshape( (1, img_height*img_width) )\n",
    "    #print(ax_2D.shape)    \n",
    "    predictions =  loaded_model.predict(ax_2D)\n",
    "    print(f, predictions[0])\n",
    "    #break\n",
    "    \n",
    "    \n",
    "\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print type(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
